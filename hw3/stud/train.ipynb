{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move this notebook into the main folder before execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer and embedder model from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "\n",
    "delimitaror = [\"<a>\",\"</a>\",\"<b>\",\"</b>\",\"<p>\"]\n",
    "\n",
    "\n",
    "#FOLLOWING PAPER ... WE CAN ADD SOME DELIMITATORS TO INDEFIFY STARTING AND FINISHING POSITION OF \n",
    "#ENTITY A, ENTITY B, Pronoun\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\",never_split=delimitaror)\n",
    "tokenizer.add_tokens(delimitaror,special_tokens=True)\n",
    "\n",
    "\n",
    "auto_model = AutoModel.from_pretrained(\"bert-base-cased\",output_hidden_states=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from  typing import Dict,List,Tuple\n",
    "import pandas as pd\n",
    "from hw3.evaluate import read_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CoreferenceDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer,\n",
    "        modality: str, \n",
    "        data_path : str, \n",
    "        truncate_up_to_pron: bool=True, \n",
    "        labeled: bool=True,\n",
    "        inference : bool = False \n",
    "    ):\n",
    "\n",
    "        modality = modality+\".tsv\"\n",
    "        self.folder = os.path.join(data_path,modality)\n",
    "        self.truncate_up_to_pron = truncate_up_to_pron\n",
    "        self.labeled = labeled\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #self.data = pd.read_csv(filepath_or_buffer=self.folder, sep=\"\\t\")\n",
    "        self.data = read_dataset(self.folder)\n",
    "    \n",
    "\n",
    "        \n",
    "        self.pronoun = \"<p>\",\n",
    "        self.A_start = \"<a>\",\n",
    "        self.A_finish = \"</a>\",\n",
    "        self.B_start =  \"<b>\",\n",
    "        self.B_finish =  \"</b>\"\n",
    "\n",
    "        CLS = [self.tokenizer.cls_token]\n",
    "        SEP = [self.tokenizer.sep_token]\n",
    "\n",
    "        self.CLS = CLS\n",
    "        self.SEP = SEP\n",
    "\n",
    "        if inference :\n",
    "            pass\n",
    "        else :            \n",
    "            self.dataset = self.pre_processing(CLS,SEP)\n",
    "        \n",
    "    def pre_processing(self,CLS,SEP):\n",
    "\n",
    "        dataset = []\n",
    "\n",
    "    \n",
    "        for i, row in enumerate(self.data):\n",
    "            elements = dict()\n",
    "\n",
    "            tokens, offsets = self.tokenize_sentence(row)\n",
    "\n",
    "    \n",
    " \n",
    "            \n",
    "            pronoun = tokens[offsets[\"<p>\"][0]]\n",
    "            A_entity = tokens[offsets[\"<a>\"][0]:offsets[\"</a>\"][0]]\n",
    "            B_entity = tokens[offsets[\"<b>\"][0]:offsets[\"</b>\"][0]]\n",
    "\n",
    "\n",
    "            nothing = CLS + tokens + SEP + [pronoun, \"is\", \"neither\"] + SEP\n",
    "            A_sentence = CLS + tokens + SEP + [pronoun, \"is\"] + A_entity + SEP\n",
    "            B_sentence = CLS + tokens + SEP + [pronoun, \"is\"] + B_entity + SEP   \n",
    "            \n",
    "            \n",
    "            list_alternatives = [nothing,A_sentence, B_sentence]\n",
    "            tokens_list = []\n",
    "\n",
    "            for instances in list_alternatives :\n",
    "                tokens_list.append(self.tokenizer.convert_tokens_to_ids(instances))\n",
    "            \n",
    "\n",
    "            elements['tokens'] = tokens_list\n",
    "            elements['offsets'] = self._get_offsets_list(offsets)\n",
    "\n",
    "\n",
    "\n",
    "            #generate gt \n",
    "            if row['is_coref_A'] in [\"TRUE\", True]:\n",
    "                elements['labels'] = 1\n",
    "\n",
    "            elif row['is_coref_B'] in [\"TRUE\", True]:\n",
    "                elements['labels'] = 2\n",
    "\n",
    "            else:\n",
    "                elements['labels'] = 0\n",
    "\n",
    "            dataset.append(elements)         \n",
    "        return dataset \n",
    "  \n",
    "    def _get_offsets_list(self, offsets: Dict[str, List[int]]) -> List[int]:\n",
    "        # 1 is added for the introduction of the CLS token\n",
    "        offsets_A = [offsets[\"<a>\"][0] + 1, offsets[\"</a>\"][0] + 1]\n",
    "        offsets_B = [offsets[\"<b>\"][0] + 1, offsets[\"</b>\"][0] + 1]\n",
    "        \n",
    "        return  [offsets[\"<p>\"][0] + 1] + offsets_A + offsets_B\n",
    "  \n",
    "    def _insert_tag(self, text: str, offsets: Tuple[int, int], \n",
    "                    start_tag: str, end_tag: str = None) -> str:\n",
    "        start_off, end_off = offsets \n",
    "\n",
    "        # Starting tag only\n",
    "        if end_tag is None:\n",
    "            text = text[:start_off] + start_tag + text[start_off:]\n",
    "            return text\n",
    "\n",
    "        text = text[:start_off] + start_tag + text[start_off:end_off] + end_tag + text[end_off:]\n",
    "        return text\n",
    "\n",
    "    def tokenize_sentence(self, row: Dict):\n",
    "        tag_labels = {\n",
    "            \"pronoun_tag\": \"<p>\",\n",
    "            \"start_A_tag\": \"<a>\",\n",
    "            \"end_A_tag\": \"</a>\",\n",
    "            \"start_B_tag\": \"<b>\",\n",
    "            \"end_B_tag\": \"</b>\"\n",
    "        }\n",
    "        \n",
    "        tokens = []\n",
    "        tag_labels = tag_labels\n",
    "        offsets = {tag: [] for tag in tag_labels.values()}\n",
    "\n",
    "\n",
    "\n",
    "        text = row['text']\n",
    "        pronoun = row['pron']\n",
    "        A_entity = row['entity_A']\n",
    "        B_entity = row['entity_B']\n",
    "\n",
    "        # Sort the offsets in ascending order\n",
    "        break_points = sorted([\n",
    "            (tag_labels[\"pronoun_tag\"], row['p_offset']),\n",
    "            (tag_labels[\"start_A_tag\"], row['offset_A']),\n",
    "            (tag_labels[\"end_A_tag\"], row['offset_A'] + len(A_entity)),\n",
    "            (tag_labels[\"start_B_tag\"], row['offset_B']),\n",
    "            (tag_labels[\"end_B_tag\"], row['offset_B'] + len(B_entity)),\n",
    "        ], key=lambda x: x[1])\n",
    "\n",
    "        # When a new tag is inserted, the offset of the next tag\n",
    "        # changes by the length of the inserted tag.\n",
    "        len_added_tags = 0\n",
    "        for tag, offset in break_points:\n",
    "            offset += len_added_tags\n",
    "            text = self._insert_tag(text, (offset, None), tag)\n",
    "            len_added_tags += len(tag)\n",
    "\n",
    "        # Truncate the text at the last tag inserted and append the pronoun at the end\n",
    "        if self.truncate_up_to_pron:\n",
    "            text = text[:offset+len(tag)] + pronoun\n",
    "\n",
    "        # Also the tags are added to the tokens\n",
    "        for token in self.tokenizer.tokenize(text):    \n",
    "            tokens.append(token)\n",
    "\n",
    "            if token in [*tag_labels.values()]:\n",
    "                if \"/\" in token: # End token\n",
    "                    offsets[token].append(len(tokens)-1)\n",
    "                else:\n",
    "                    offsets[token].append(len(tokens)) \n",
    "        \n",
    "\n",
    "     \n",
    "        \n",
    "        return tokens, offsets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "    def prapare_batch (self,batch,device):\n",
    "        \n",
    "\n",
    "        batch = []\n",
    "\n",
    "    \n",
    "        for i, instance in enumerate(batch):\n",
    "            elements = dict()\n",
    "\n",
    "            tokens, offsets = self.tokenize_sentence(instance)\n",
    "\n",
    "\n",
    "            \n",
    "            pronoun = tokens[offsets[\"<p>\"][0]]\n",
    "            A_entity = tokens[offsets[\"<a>\"][0]:offsets[\"</a>\"][0]]\n",
    "            B_entity = tokens[offsets[\"<b>\"][0]:offsets[\"</b>\"][0]]\n",
    "\n",
    "\n",
    "            nothing = self.CLS + tokens + self.SEP + [pronoun, \"is\", \"neither\"] + self.SEP\n",
    "            A_sentence = self.CLS + tokens + self.SEP + [pronoun, \"is\"] + A_entity + self.SEP\n",
    "            B_sentence = self.CLS + tokens + self.SEP + [pronoun, \"is\"] + B_entity + self.SEP   \n",
    "            \n",
    "            \n",
    "            list_alternatives = [nothing,A_sentence, B_sentence]\n",
    "            tokens_list = []\n",
    "\n",
    "            for instances in list_alternatives :\n",
    "                tokens_list.append(self.tokenizer.convert_tokens_to_ids(instances))\n",
    "            \n",
    "\n",
    "            elements['tokens'] = tokens_list\n",
    "            elements['offsets'] = self._get_offsets_list(offsets)\n",
    "            batch.append(elements)  \n",
    "\n",
    "        #GET MAX LENGHT\n",
    "        #total number of lists = batch_size x 3\n",
    "        pad: int=0\n",
    "        truncate: int=512\n",
    "\n",
    "        input = {}\n",
    "        list_ = []\n",
    "        batch_size = len(batch)\n",
    "        total_n_sequences = batch_size*3\n",
    "        \n",
    "        for samples in batch :\n",
    "            list_.append(samples[\"tokens\"][0])\n",
    "            list_.append(samples[\"tokens\"][1])\n",
    "            list_.append(samples[\"tokens\"][2])\n",
    "    \n",
    "\n",
    "        max_len = min(max((len(x) for x in list_)),truncate)\n",
    "\n",
    "        \n",
    "        \n",
    "        zero_padding = np.full((total_n_sequences, max_len), pad, dtype=np.int64)\n",
    "\n",
    "\n",
    "        #insert each token sequence in the geneted sentence\n",
    "        for i,tokens in enumerate(list_):\n",
    "            lenght_original_tonized_sequnce = len(tokens)\n",
    "            zero_padding[i,:lenght_original_tonized_sequnce] = tokens\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        tokens_padded = torch.tensor(zero_padding, device=device)\n",
    "        tokens_padded = tokens_padded.view(batch_size,3,max_len)\n",
    "        \n",
    "\n",
    "        input[\"tokens\"] = tokens_padded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return input\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing pre processing and CoreferenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge ( Peppy ) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois. <a> MacKenzie </a> studied with <b> Bernard Leach </b> from 1949 to 1952. <p> His [SEP] His is MacKenzie [SEP]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data ='data'\n",
    "train_ds = CoreferenceDataset(tokenizer,\"train\",path_data)\n",
    "dev_ds = CoreferenceDataset(tokenizer,\"dev\",path_data)\n",
    "\n",
    "\n",
    "#check pre-processing procedure\n",
    "test = train_ds.__getitem__(0)\n",
    "tokenizer.decode(test[\"tokens\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] He grew up in Evanston, Illinois the second oldest of five children including his brothers, Fred and Gordon and sisters, Marge ( Peppy ) and Marilyn. His high school days were spent at New Trier High School in Winnetka, Illinois. <a> MacKenzie </a> studied with <b> Bernard Leach </b> from 1949 to 1952. <p> His [SEP] His is neither [SEP]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_ds.__getitem__(0)\n",
    "tokenizer.decode(test[\"tokens\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader and custom collated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataloader = DataLoader(train_ds, batch_size=batch_size, \\n                              collate_fn=collate_function, shuffle=True)\\n\\nvalid_dataloader = DataLoader(dev_ds, batch_size=batch_size, \\n                              collate_fn=collate_function, shuffle=False)\\n\\nfor data in train_dataloader:\\n    print(data[\"tokens\"].size())\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def collate_function(data:list, device: str=\"cuda:0\", pad: int=0, truncate: int=512):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    data, list of samples, each is a dictionary with keys \"tokens\",\"offset\",\"labels\".\n",
    "    device, in general is \"cuda:0\" \n",
    "    pad, value used for padding, BERT token for padding is 0\n",
    "    truncate : lenght of element to truncate\n",
    "    \n",
    "    Return: \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #GET MAX LENGHT\n",
    "    #total number of lists = batch_size x 3\n",
    "    input = {}\n",
    "    list_ = []\n",
    "    labels = []\n",
    "    batch_size = len(data)\n",
    "    total_n_sequences = batch_size*3\n",
    "    \n",
    "    for samples in data :\n",
    "        list_.append(samples[\"tokens\"][0])\n",
    "        list_.append(samples[\"tokens\"][1])\n",
    "        list_.append(samples[\"tokens\"][2])\n",
    "        labels.append(samples[\"labels\"])\n",
    "    \n",
    "\n",
    "\n",
    "    max_len = min(max((len(x) for x in list_)),truncate)\n",
    "\n",
    "    \n",
    "    \n",
    "    zero_padding = np.full((total_n_sequences, max_len), pad, dtype=np.int64)\n",
    "\n",
    "\n",
    "    #insert each token sequence in the geneted sentence\n",
    "    for i,tokens in enumerate(list_):\n",
    "        lenght_original_tonized_sequnce = len(tokens)\n",
    "        zero_padding[i,:lenght_original_tonized_sequnce] = tokens\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    tokens_padded = torch.tensor(zero_padding, device=device)\n",
    "    tokens_padded = tokens_padded.view(batch_size,3,max_len)\n",
    "    \n",
    "\n",
    "\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.uint8, device=device)\n",
    "\n",
    "    input[\"tokens\"] = tokens_padded\n",
    "    input[\"labels\"] = labels_tensor\n",
    "\n",
    "    return input\n",
    "\n",
    "\"\"\"\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_function, shuffle=True)\n",
    "\n",
    "valid_dataloader = DataLoader(dev_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_function, shuffle=False)\n",
    "\n",
    "for data in train_dataloader:\n",
    "    print(data[\"tokens\"].size())\n",
    "\"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Resolution models and Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConferenceResolution(nn.Module):\n",
    "\n",
    "    def __init__(self, bert_model,tokenizer,config):\n",
    "        super().__init__()\n",
    "        # note  : config is not needed with this deployment case\n",
    "        self.bert_model = bert_model\n",
    "\n",
    "        self.bert_model.resize_token_embeddings(len(tokenizer.vocab))\n",
    "        self.criterion= torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.normalize = nn.BatchNorm1d(768)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(768, 1)\n",
    "\n",
    "\n",
    "        self.classifier0 = nn.Linear(768, 768)\n",
    "        self.classifier1 = nn.Linear(768, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    def forward(self, sample):\n",
    "        #[Batch,3,Tokens]\n",
    "        bert_input = sample['tokens']\n",
    "        \n",
    "        b,_,l = bert_input.size()\n",
    "\n",
    "\n",
    "        #[Batch*3,Tokens]\n",
    "        bert_input = bert_input.view(-1,l)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #[Batch*3,Tokens,hidden_size]\n",
    "        \n",
    "        bert_outputs = self.bert_model(bert_input, attention_mask=(bert_input > 0).long(),token_type_ids=None, output_hidden_states=True)\n",
    "\n",
    "        out = bert_outputs.pooler_output\n",
    "\n",
    "        #from CLS extraction\n",
    "        #[Batch*3,1,hidden_size]\n",
    "        #[Batch*3,hidden_size]\n",
    "        pooled_output = self.normalize(out)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        #[Batch*3]\n",
    "        #logits = self.classifier(pooled_output)\n",
    "        logits = self.classifier0(pooled_output)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.dropout0(logits)\n",
    "        logits = self.classifier1(logits)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        #[Batch,3]\n",
    "        output = logits.view(-1, 3)\n",
    "        loss = None\n",
    "\n",
    "        if self.train:\n",
    "            labels = sample['labels']\n",
    "            loss = self.criterion(output, labels)\n",
    "\n",
    "        return output,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs n. 0\n",
      "F1 train: [0.69752066 0.87819549 0.88465763]\n",
      "F1 eval: [0.61261261 0.8        0.8056872 ]\n",
      "Epochs n. 1\n",
      "F1 train: [0.86731392 0.92865232 0.93001099]\n",
      "F1 eval: [0.61261261 0.79365079 0.79713604]\n",
      "Epochs n. 2\n",
      "F1 train: [0.87797147 0.95065913 0.94907749]\n",
      "F1 eval: [0.6        0.79795396 0.80095923]\n",
      "Epochs n. 3\n",
      "F1 train: [0.90393701 0.96015038 0.96038504]\n",
      "F1 eval: [0.6        0.78740157 0.79156909]\n",
      "Epochs n. 4\n",
      "F1 train: [0.92068429 0.96676737 0.97227357]\n",
      "F1 eval: [0.60377358 0.78306878 0.79716981]\n",
      "Epochs n. 5\n",
      "F1 train: [0.94573643 0.97917456 0.98081181]\n",
      "F1 eval: [0.6440678  0.79144385 0.79807692]\n",
      "Epochs n. 6\n",
      "F1 train: [0.96583851 0.98715042 0.98891353]\n",
      "F1 eval: [0.66115702 0.77628032 0.80769231]\n",
      "Epochs n. 7\n",
      "F1 train: [0.95193798 0.98451077 0.98446746]\n",
      "F1 eval: [0.64285714 0.80104712 0.80193237]\n",
      "Epochs n. 8\n",
      "F1 train: [0.97017268 0.99132403 0.98818316]\n",
      "F1 eval: [0.61261261 0.79274611 0.79318735]\n",
      "Epochs n. 9\n",
      "F1 train: [0.96865204 0.99322289 0.99481865]\n",
      "F1 eval: [0.60952381 0.81038961 0.81339713]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "writer = SummaryWriter()\n",
    "\n",
    "config = {}\n",
    "model = ConferenceResolution(auto_model,tokenizer,config).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.000004)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.96)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_function, shuffle=True)\n",
    "valid_dataloader = DataLoader(dev_ds, batch_size=batch_size, \n",
    "                              collate_fn=collate_function, shuffle=False)\n",
    "\n",
    "scaler = GradScaler()\n",
    "                              \n",
    "\n",
    "EPOCHS = 20\n",
    "patience_counter = 0\n",
    "patience = 8\n",
    "max_val_loss = 9999\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    #TRAINING\n",
    "    p = []\n",
    "    g = []\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    losses_eval = 0\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "        \n",
    "            output,loss = model(sample_batched)\n",
    "            #loss.backward()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),0.6)\n",
    "\n",
    "            \n",
    "            ### Update weights ### \n",
    "        \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            #optimizer.step()\n",
    "            #print(\"Loss\",loss)\n",
    "           \n",
    "\n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            labels = sample_batched['labels']\n",
    "            p += predicted.tolist()\n",
    "            g += labels.tolist()\n",
    "\n",
    "            losses += loss.detach()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-------------------------RESULTS----------------------------------\n",
    "    print(\"Epochs n.\", epoch)\n",
    "   \n",
    "    f1_ =  f1_score(g, p, average=None)\n",
    "    f1_avg =  f1_score(g, p, average=\"weighted\")\n",
    "    print(\"F1 train:\",f1_)\n",
    "    scheduler.step()\n",
    "    losses = losses/train_dataloader.batch_size\n",
    "    writer.add_scalar(\"Loss/train\", losses, epoch)\n",
    "    writer.add_scalar(\"result/train\", f1_avg, epoch)\n",
    "\n",
    "\n",
    " \n",
    "    #EVALUATION\n",
    "    p = []\n",
    "    g = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(valid_dataloader):\n",
    "        \n",
    "        \n",
    "            output,loss = model(sample_batched)\n",
    "\n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            labels = sample_batched['labels']\n",
    "            p += predicted.tolist()\n",
    "            g += labels.tolist()\n",
    "            losses_eval += loss.detach()\n",
    "    \n",
    "    #-------------------------RESULTS----------------------------------\n",
    "    f1_ =  f1_score(g, p, average=None)\n",
    "    f1_avg =  f1_score(g, p, average=\"weighted\")\n",
    "    print(\"F1 eval:\",f1_)\n",
    "    losses_eval = losses_eval/valid_dataloader.batch_size\n",
    "    writer.add_scalar(\"Loss/eval\", losses_eval, epoch)\n",
    "    writer.add_scalar(\"result/eval\", f1_avg, epoch)\n",
    "\n",
    "\n",
    "    if max_val_loss > losses_eval:\n",
    "        max_val_loss = losses_eval \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter > patience:\n",
    "        torch.save(model.state_dict(), \"hw3/saved/model.pth\")\n",
    "        torch.save(model.bert_model, \"hw3/saved/model.pth\")        \n",
    "        #model.bert_model.save_pretrained(\"hw3/saved/model_bert.pth\")\n",
    "        cm = confusion_matrix(g, p)\n",
    "        break\n",
    "\n",
    "    \"\"\"\n",
    "    if f1_avg_max < f1_avg:\n",
    "        f1_avg_max = f1_avg \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter > patience:\n",
    "        torch.save(model.state_dict(), \"hw3/saved/model.pth\")\n",
    "        model.bert_model.save_pretrained(\"hw3/saved/model_bert.pth\")\n",
    "        cm = confusion_matrix(g, p)\n",
    "        break\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mcm\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(cm, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_docstring' from 'matplotlib' (/home/mv/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m     \n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/__init__.py:2\u001b[0m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrcmod\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpalettes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py:7\u001b[0m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcycler\u001b[39;00m \u001b[39mimport\u001b[39;00m cycler\n\u001b[0;32m----> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m palettes\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=9'>10</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mset_theme\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreset_defaults\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreset_orig\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=10'>11</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39maxes_style\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_style\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mplotting_context\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_context\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=11'>12</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mset_palette\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=14'>15</a>\u001b[0m _style_keys \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maxes.facecolor\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=51'>52</a>\u001b[0m \n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/rcmod.py?line=52'>53</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py:9\u001b[0m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m      <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexternal\u001b[39;00m \u001b[39mimport\u001b[39;00m husl\n\u001b[0;32m----> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m desaturate, get_color_cycle\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m xkcd_rgb, crayons\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=12'>13</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcolor_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhls_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhusl_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmpl_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=13'>14</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mdark_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlight_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdiverging_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=14'>15</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mblend_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mxkcd_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcrayon_palette\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/palettes.py?line=15'>16</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mcubehelix_palette\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_color_codes\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py:14\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmplcol\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize_kwargs\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=17'>18</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdesaturate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaturate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mset_hls_values\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmove_legend\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/seaborn/utils.py?line=18'>19</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mdespine\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mget_dataset_names\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mget_data_home\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mload_dataset\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py:57\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py?line=54'>55</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m docstring\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py?line=55'>56</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase, MouseButton\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py?line=56'>57</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfigure\u001b[39;00m \u001b[39mimport\u001b[39;00m Figure, figaspect\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py?line=57'>58</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgridspec\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/pyplot.py?line=58'>59</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py:25\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _blocking_input, docstring, projections\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39martist\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=26'>27</a>\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/figure.py?line=28'>29</a>\u001b[0m     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py:58\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py?line=55'>56</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeo\u001b[39;00m \u001b[39mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py?line=56'>57</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolar\u001b[39;00m \u001b[39mimport\u001b[39;00m PolarAxes\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py?line=57'>58</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmpl_toolkits\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmplot3d\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes3D\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py?line=60'>61</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mProjectionRegistry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/projections/__init__.py?line=61'>62</a>\u001b[0m     \u001b[39m\"\"\"A mapping of registered projection names to projection classes.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maxes3d\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes3D\n\u001b[1;32m      <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/__init__.py?line=2'>3</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAxes3D\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:22\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook, _docstring, _preprocess_data\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py?line=22'>23</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39martist\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmartist\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maxes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmaxes\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_docstring' from 'matplotlib' (/home/mv/miniconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/matplotlib/__init__.py)"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Nothing', 'Entity A',\"Entity B\"]); ax.yaxis.set_ticklabels(['Nothing', 'Entity A',\"Entity B\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
